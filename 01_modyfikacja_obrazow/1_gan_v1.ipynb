{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "import cv2\n",
    "import lpips\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchmetrics\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.models.vgg import vgg16\n",
    "from torchvision.transforms import (CenterCrop, Compose, RandomCrop, Resize,\n",
    "                                    ToPILImage, ToTensor)\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:16.367353Z",
     "iopub.status.busy": "2025-03-23T17:51:16.367054Z",
     "iopub.status.idle": "2025-03-23T17:51:30.088539Z",
     "shell.execute_reply": "2025-03-23T17:51:30.087491Z",
     "shell.execute_reply.started": "2025-03-23T17:51:16.367331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def initialize_metrics(device):\n",
    "    return {\n",
    "        \"mse\": nn.MSELoss().to(device),\n",
    "        \"psnr\": torchmetrics.PeakSignalNoiseRatio(data_range=1.0).to(device),\n",
    "        \"ssim\": torchmetrics.StructuralSimilarityIndexMeasure(data_range=1.0).to(device),\n",
    "        \"lpips\": lpips.LPIPS(net=\"alex\").to(device)\n",
    "    }\n",
    "\n",
    "def compute_metrics(metrics_fns, prediction, target):\n",
    "    return {\n",
    "        \"mse\": metrics_fns[\"mse\"](prediction, target).item(),\n",
    "        \"psnr\": metrics_fns[\"psnr\"](prediction, target).item(),\n",
    "        \"ssim\": metrics_fns[\"ssim\"](prediction, target).item(),\n",
    "        \"lpips\": metrics_fns[\"lpips\"](prediction, target).item()\n",
    "    }\n",
    "\n",
    "def process_image_batch(lr_img, hr_img, model, device):\n",
    "    lr_img = lr_img.unsqueeze(0).to(device)\n",
    "    hr_img = hr_img.unsqueeze(0).to(device)\n",
    "    lr_np = lr_img.squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "    bicubic_np = cv2.resize(lr_np, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "    bicubic = torch.tensor(bicubic_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    model_output = torch.clip(model(lr_img), 0, 1)\n",
    "    return lr_img, hr_img, bicubic, model_output\n",
    "\n",
    "def visualize_image(lr_img, hr_img, bicubic, model_output, ax_row, metrics_bicubic, metrics_model):\n",
    "    for ax, img, title in zip(ax_row, \n",
    "                              [lr_img, hr_img, bicubic, model_output], \n",
    "                              [\"Low Res (64x64)\", \"High Res (256x256)\", \"Bicubic Interpolation\", \"Model Output\"]):\n",
    "        img_np = img.squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img_np)\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    ax_row[2].text(0.5, -0.15, f\"MSE: {metrics_bicubic['mse']:.4f}, PSNR: {metrics_bicubic['psnr']:.2f}\\n\"\n",
    "                   f\"SSIM: {metrics_bicubic['ssim']:.4f}, LPIPS: {metrics_bicubic['lpips']:.4f}\",\n",
    "                   transform=ax_row[2].transAxes, ha=\"center\", fontsize=10)\n",
    "    ax_row[3].text(0.5, -0.15, f\"MSE: {metrics_model['mse']:.4f}, PSNR: {metrics_model['psnr']:.2f}\\n\"\n",
    "                   f\"SSIM: {metrics_model['ssim']:.4f}, LPIPS: {metrics_model['lpips']:.4f}\",\n",
    "                   transform=ax_row[3].transAxes, ha=\"center\", fontsize=10)\n",
    "\n",
    "def evaluate_and_visualize(model, dataset, n=5, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    metrics_fns = initialize_metrics(device)\n",
    "    all_metrics = {\"bicubic\": {\"mse\": [], \"psnr\": [], \"ssim\": [], \"lpips\": []},\n",
    "                   \"model\": {\"mse\": [], \"psnr\": [], \"ssim\": [], \"lpips\": []}}\n",
    "    with torch.no_grad():\n",
    "        for lr_img, hr_img in dataset:\n",
    "            lr_img, hr_img, bicubic, model_output = process_image_batch(lr_img, hr_img, model, device)\n",
    "            bicubic_metrics = compute_metrics(metrics_fns, bicubic, hr_img)\n",
    "            model_metrics = compute_metrics(metrics_fns, model_output, hr_img)\n",
    "            for metric in all_metrics[\"bicubic\"]:\n",
    "                all_metrics[\"bicubic\"][metric].append(bicubic_metrics[metric])\n",
    "                all_metrics[\"model\"][metric].append(model_metrics[metric])\n",
    "    avg_metrics = {\n",
    "        method: {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "        for method, metrics in all_metrics.items()\n",
    "    }\n",
    "    indices = np.random.choice(len(dataset), n, replace=False)\n",
    "    samples = [dataset[idx] for idx in indices]\n",
    "    fig, axes = plt.subplots(n, 4, figsize=(20, 5 * n))\n",
    "    with torch.no_grad():\n",
    "        for i, (lr_img, hr_img) in enumerate(samples):\n",
    "            lr_img, hr_img, bicubic, model_output = process_image_batch(lr_img, hr_img, model, device)\n",
    "            bicubic_metrics = compute_metrics(metrics_fns, bicubic, hr_img)\n",
    "            model_metrics = compute_metrics(metrics_fns, model_output, hr_img)\n",
    "            ax_row = axes[i] if n > 1 else axes\n",
    "            visualize_image(lr_img, hr_img, bicubic, model_output, ax_row, bicubic_metrics, model_metrics)\n",
    "    print(\"\\nŚrednie metryki dla całego datasetu walidacyjnego:\")\n",
    "    for method in [\"bicubic\", \"model\"]:\n",
    "        print(f\"{method.capitalize()} Metrics:\")\n",
    "        print(f\"MSE: {avg_metrics[method]['mse']:.4f}, PSNR: {avg_metrics[method]['psnr']:.2f}, \"\n",
    "              f\"SSIM: {avg_metrics[method]['ssim']:.4f}, LPIPS: {avg_metrics[method]['lpips']:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.090531Z",
     "iopub.status.busy": "2025-03-23T17:51:30.089834Z",
     "iopub.status.idle": "2025-03-23T17:51:30.102125Z",
     "shell.execute_reply": "2025-03-23T17:51:30.101274Z",
     "shell.execute_reply.started": "2025-03-23T17:51:30.090506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super().__init__()\n",
    "        upsample_block_num = int(math.log(scale_factor, 2))\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4), nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(64) for _ in range(5)]\n",
    "        )\n",
    "        \n",
    "        self.block7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "        self.block8 = nn.Sequential(\n",
    "            *[UpsampleBLock(64, 2) for _ in range(upsample_block_num)],\n",
    "            nn.Conv2d(64, 3, kernel_size=9, padding=4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        residual = self.residual_blocks(block1)\n",
    "        block7 = self.block7(residual)\n",
    "        block8 = self.block8(block1 + block7)\n",
    "        return (torch.tanh(block8) + 1) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._conv_block(3, 64, 3, 1, False),\n",
    "            self._conv_block(64, 64, 3, 2),\n",
    "            self._conv_block(64, 128, 3, 1),\n",
    "            self._conv_block(128, 128, 3, 2),\n",
    "            self._conv_block(128, 256, 3, 1),\n",
    "            self._conv_block(256, 256, 3, 2),\n",
    "            self._conv_block(256, 512, 3, 1),\n",
    "            self._conv_block(512, 512, 3, 2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def _conv_block(self, in_channels, out_channels, kernel_size, stride, batch_norm=True):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        if batch_norm:\n",
    "            layers.insert(1, nn.BatchNorm2d(out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x).view(x.size(0)))\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class UpsampleBLock(nn.Module):\n",
    "    def __init__(self, in_channels, up_scale):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * up_scale ** 2, 3, padding=1),\n",
    "            nn.PixelShuffle(up_scale),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.104024Z",
     "iopub.status.busy": "2025-03-23T17:51:30.103743Z",
     "iopub.status.idle": "2025-03-23T17:51:30.123032Z",
     "shell.execute_reply": "2025-03-23T17:51:30.122263Z",
     "shell.execute_reply.started": "2025-03-23T17:51:30.104003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        self.loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in self.loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "    \n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super().__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, _, h_x, w_x = x.size()\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :-1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :-1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / self.tensor_size(x[:, :, 1:, :]) + w_tv / self.tensor_size(x[:, :, :, 1:])) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.numel() // t.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.124397Z",
     "iopub.status.busy": "2025-03-23T17:51:30.124173Z",
     "iopub.status.idle": "2025-03-23T17:51:30.139298Z",
     "shell.execute_reply": "2025-03-23T17:51:30.138592Z",
     "shell.execute_reply.started": "2025-03-23T17:51:30.124378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg'])\n",
    "\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "\n",
    "def train_hr_transform(crop_size):\n",
    "    return Compose([RandomCrop(crop_size), ToTensor()])\n",
    "\n",
    "\n",
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return Compose([ToPILImage(), Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC), ToTensor()])\n",
    "\n",
    "\n",
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        super().__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "        self.rotation_angles = [0, 90, 180, 270]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index]).convert('RGB')\n",
    "        hr_image = TF.rotate(hr_image, random.choice(self.rotation_angles))\n",
    "        hr_image = self.hr_transform(hr_image)\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n",
    "class ValDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super().__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index])\n",
    "        crop_size = calculate_valid_crop_size(min(hr_image.size), self.upscale_factor)\n",
    "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
    "        hr_image = CenterCrop(crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        return ToTensor()(lr_image), ToTensor()(hr_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.140443Z",
     "iopub.status.busy": "2025-03-23T17:51:30.140111Z",
     "iopub.status.idle": "2025-03-23T17:51:30.662711Z",
     "shell.execute_reply": "2025-03-23T17:51:30.662049Z",
     "shell.execute_reply.started": "2025-03-23T17:51:30.140413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_gan(config):\n",
    "    train_set = TrainDatasetFromFolder(config[\"TRAIN_DATA_PATH\"], crop_size=config[\"CROP_SIZE\"], upscale_factor=config[\"UPSCALE_FACTOR\"])\n",
    "    val_set = ValDatasetFromFolder(config[\"VAL_DATA_PATH\"], upscale_factor=config[\"UPSCALE_FACTOR\"])\n",
    "    train_loader = DataLoader(dataset=train_set, num_workers=config[\"NUM_WORKERS\"], batch_size=config[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "    netG = Generator(config[\"UPSCALE_FACTOR\"])\n",
    "    netD = Discriminator()\n",
    "\n",
    "    generator_criterion = GeneratorLoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        netG.cuda()\n",
    "        netD.cuda()\n",
    "        generator_criterion.cuda()\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters())\n",
    "    optimizerD = optim.Adam(netD.parameters())\n",
    "\n",
    "    for epoch in range(1, config[\"NUM_EPOCHS\"] + 1):\n",
    "        train_epoch(train_loader, netG, netD, generator_criterion, optimizerG, optimizerD, epoch, config[\"NUM_EPOCHS\"])\n",
    "        if epoch % 5 == 0:\n",
    "            netG.eval()\n",
    "            evaluate_and_visualize(netG, val_set)\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, netG, netD, generator_criterion, optimizerG, optimizerD, epoch, num_epochs):\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    \n",
    "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\", leave=True, dynamic_ncols=True) as train_bar:\n",
    "        for data, target in train_bar:\n",
    "            batch_size = data.size(0)\n",
    "            running_results['batch_sizes'] += batch_size\n",
    "\n",
    "            real_img = target.cuda() if torch.cuda.is_available() else target.float()\n",
    "            z = data.cuda() if torch.cuda.is_available() else data.float()\n",
    "            \n",
    "            fake_img = netG(z)\n",
    "            fake_out = netD(fake_img).mean()\n",
    "\n",
    "            optimizerG.zero_grad()\n",
    "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "            g_loss.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            real_out = netD(real_img).mean()\n",
    "            fake_out = netD(fake_img.detach()).mean()\n",
    "            d_loss = 1 - real_out + fake_out\n",
    "\n",
    "            optimizerD.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            running_results['g_loss'] += g_loss.item() * batch_size\n",
    "            running_results['d_loss'] += d_loss.item() * batch_size\n",
    "            running_results['d_score'] += real_out.item() * batch_size\n",
    "            running_results['g_score'] += fake_out.item() * batch_size\n",
    "\n",
    "            train_bar.set_postfix({\n",
    "                \"Loss_D\": f\"{running_results['d_loss'] / running_results['batch_sizes']:.4f}\",\n",
    "                \"Loss_G\": f\"{running_results['g_loss'] / running_results['batch_sizes']:.4f}\",\n",
    "                \"D(x)\": f\"{running_results['d_score'] / running_results['batch_sizes']:.4f}\",\n",
    "                \"D(G(z))\": f\"{running_results['g_score'] / running_results['batch_sizes']:.4f}\"\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.664011Z",
     "iopub.status.busy": "2025-03-23T17:51:30.663520Z",
     "iopub.status.idle": "2025-03-23T17:51:30.672907Z",
     "shell.execute_reply": "2025-03-23T17:51:30.672071Z",
     "shell.execute_reply.started": "2025-03-23T17:51:30.663979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T17:51:30.674040Z",
     "iopub.status.busy": "2025-03-23T17:51:30.673754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"CROP_SIZE\": 256,\n",
    "    \"UPSCALE_FACTOR\": 4,\n",
    "    \"NUM_EPOCHS\": 50,\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"NUM_WORKERS\": 4,\n",
    "    \"TRAIN_DATA_PATH\": 'data/train/256',\n",
    "    \"VAL_DATA_PATH\": 'data/valid/256'\n",
    "}\n",
    "train_gan(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"CROP_SIZE\": 256,\n",
    "    \"UPSCALE_FACTOR\": 8,\n",
    "    \"NUM_EPOCHS\": 50,\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"NUM_WORKERS\": 4,\n",
    "    \"TRAIN_DATA_PATH\": 'data/train/256',\n",
    "    \"VAL_DATA_PATH\": 'data/valid/256'\n",
    "}\n",
    "train_gan(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie\n",
    "\n",
    "Zaproponowana architektura inspirowana podejściem SRGAN osiąga nieco lepsze wyniki niż interpolacja bikubiczna.\n",
    "Obrazy generowane przez sieć są bardziej ostre niż obrazy interpolowane. Posiadają jednak widoczne artefakty: obramówka, szachownica, zduplikowane krawędzie. \n",
    "Trening przy GAN szybko przestał uwzględniać dyskryminator, który stawał się zbyt słaby i \n",
    "zawsze klasyfikował obrazy jako realistyczne, przez co generator nie otrzymuje gradientów od dyskryminatora i \n",
    "w zasadzie trening staje się zwykłym treningiem generatora a nie GAN. Uczenie dłuższe niż 50 epok mogłoby nieco poprawić generacje,\n",
    "ponieważ metryki cały czas się nieznacznie poprawiały ale zdecydowano zamiast tego podjąć próbę poprawy treningu GAN"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6893332,
     "sourceId": 11063018,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
